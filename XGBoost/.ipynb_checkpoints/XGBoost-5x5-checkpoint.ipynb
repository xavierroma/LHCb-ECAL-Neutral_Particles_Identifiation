{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5x5\n",
    "# Change a flag and run all the notebook.\n",
    "#Flags\n",
    "\n",
    "KFolds = 10\n",
    "rotateToTop = True\n",
    "\n",
    "#Only one should be selected\n",
    "original = False\n",
    "preOriginal = False\n",
    "rawDigEi = False\n",
    "\n",
    "rawCLEi = False\n",
    "rawCLEi_and_original = True\n",
    "rawCLEi_and_preOriginal = False\n",
    "\n",
    "rawDigEi_and_original = False\n",
    "rawCLEi_and_original_and_preOriginal = False\n",
    "\n",
    "\n",
    "#For plotting Clusters\n",
    "plot_analysis = False\n",
    "\n",
    "#For saving boosters and their results. If selected you must specify the following variables\n",
    "save_results = True\n",
    "\n",
    "\n",
    "if rawCLEi:\n",
    "    folder = '5x5_RawClEi'\n",
    "    title = '5x5 Raw ClEi Data'\n",
    "elif rawDigEi:\n",
    "    folder = '5x5_RawDigEi'\n",
    "    title = '5x5 Raw DigEi Data'\n",
    "elif original:\n",
    "    folder = 'Original'\n",
    "    title = 'Original Data'\n",
    "elif preOriginal:\n",
    "    folder = 'preOriginal'\n",
    "    title = 'PreOriginal Data'\n",
    "elif rawCLEi_and_original:\n",
    "    folder = '5x5_RawCLEi_and_original'\n",
    "    title = '5x5 Raw ClEi & Original Data'\n",
    "elif rawDigEi_and_original:\n",
    "    folder = '5x5_RawDigEi_and_original'\n",
    "    title = '5x5 Raw DigEi & Original Data'\n",
    "elif rawCLEi_and_preOriginal:\n",
    "    folder = '5x5_RawCLEi_and_preOriginal'\n",
    "    title = '5x5 Raw ClEi & PreOriginal Data'\n",
    "elif rawCLEi_and_original_and_preOriginal:\n",
    "    folder = '5x5_RawCLEi_and_original_and_preOriginal'\n",
    "    title = '5x5 Raw ClEi & Original & PreOriginal Data'\n",
    "\n",
    "#Path to save the boosters\n",
    "save_boosters_path = './boost_models/%s/' % folder\n",
    "#Path to save the boosters image results\n",
    "save_results_path = './Outputs/%s/' % folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "photons_data = pd.read_csv('../data/MCUpgrade_photons_5x5.dat', sep='\\t')\n",
    "mergedpi_data = pd.read_csv('../data/MCUpgrade_mergedpi0_5x5.dat', sep='\\t')\n",
    "photons_data.columns = ['p', 'pt', 'eta', 'area', 'nPVs', 'ClusterE', 'ClusterE9',\n",
    "       'ClE1', 'ClE2', 'ClE3', 'ClE4', 'ClE5', 'ClE6', 'ClE7',\n",
    "       'ClE8', 'ClE9', 'ClE10', 'ClE11', 'ClE12', 'ClE13',\n",
    "       'ClE14', 'ClE15', 'ClE16', 'ClE17', 'ClE18', 'ClE19',\n",
    "       'ClE20', 'ClE21', 'ClE22', 'ClE23', 'ClE24', 'ClE25',\n",
    "       'DigE1', 'DigE2', 'DigE3', 'DigE4', 'DigE5', 'DigE6',\n",
    "       'DigE7', 'DigE8', 'DigE9', 'DigE10', 'DigE11', 'DigE12',\n",
    "       'DigE13', 'DigE14', 'DigE15', 'DigE16', 'DigE17', 'DigE18',\n",
    "       'DigE19', 'DigE20', 'DigE21', 'DigE22', 'DigE23', 'DigE24',\n",
    "       'DigE25', 'isPhr2', 'isPhr2r4', 'isPhasym', 'isPhkappa',\n",
    "       'isPhEseed', 'isPhE2', 'Sxx', 'Sxy', 'Syy']\n",
    "mergedpi_data.columns = ['p', 'pt', 'eta', 'area', 'nPVs', 'ClusterE', 'ClusterE9',\n",
    "       'ClE1', 'ClE2', 'ClE3', 'ClE4', 'ClE5', 'ClE6', 'ClE7',\n",
    "       'ClE8', 'ClE9', 'ClE10', 'ClE11', 'ClE12', 'ClE13',\n",
    "       'ClE14', 'ClE15', 'ClE16', 'ClE17', 'ClE18', 'ClE19',\n",
    "       'ClE20', 'ClE21', 'ClE22', 'ClE23', 'ClE24', 'ClE25',\n",
    "       'DigE1', 'DigE2', 'DigE3', 'DigE4', 'DigE5', 'DigE6',\n",
    "       'DigE7', 'DigE8', 'DigE9', 'DigE10', 'DigE11', 'DigE12',\n",
    "       'DigE13', 'DigE14', 'DigE15', 'DigE16', 'DigE17', 'DigE18',\n",
    "       'DigE19', 'DigE20', 'DigE21', 'DigE22', 'DigE23', 'DigE24',\n",
    "       'DigE25', 'isPhr2', 'isPhr2r4', 'isPhasym', 'isPhkappa',\n",
    "       'isPhEseed', 'isPhE2', 'Sxx', 'Sxy', 'Syy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>pt</th>\n",
       "      <th>eta</th>\n",
       "      <th>area</th>\n",
       "      <th>nPVs</th>\n",
       "      <th>ClusterE</th>\n",
       "      <th>ClusterE9</th>\n",
       "      <th>ClE1</th>\n",
       "      <th>ClE2</th>\n",
       "      <th>ClE3</th>\n",
       "      <th>...</th>\n",
       "      <th>DigE25</th>\n",
       "      <th>isPhr2</th>\n",
       "      <th>isPhr2r4</th>\n",
       "      <th>isPhasym</th>\n",
       "      <th>isPhkappa</th>\n",
       "      <th>isPhEseed</th>\n",
       "      <th>isPhE2</th>\n",
       "      <th>Sxx</th>\n",
       "      <th>Sxy</th>\n",
       "      <th>Syy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0003</td>\n",
       "      <td>3.888707</td>\n",
       "      <td>2.268885</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>19438.465517</td>\n",
       "      <td>19438.465517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.461248</td>\n",
       "      <td>...</td>\n",
       "      <td>132.5</td>\n",
       "      <td>2195.924213</td>\n",
       "      <td>0.934948</td>\n",
       "      <td>0.127382</td>\n",
       "      <td>0.266318</td>\n",
       "      <td>0.917244</td>\n",
       "      <td>0.942989</td>\n",
       "      <td>839.063615</td>\n",
       "      <td>135.916978</td>\n",
       "      <td>1356.860599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         p        pt       eta  area  nPVs      ClusterE     ClusterE9  ClE1  \\\n",
       "0  19.0003  3.888707  2.268885     0     5  19438.465517  19438.465517   0.0   \n",
       "\n",
       "   ClE2       ClE3     ...       DigE25       isPhr2  isPhr2r4  isPhasym  \\\n",
       "0   0.0  19.461248     ...        132.5  2195.924213  0.934948  0.127382   \n",
       "\n",
       "   isPhkappa  isPhEseed    isPhE2         Sxx         Sxy          Syy  \n",
       "0   0.266318   0.917244  0.942989  839.063615  135.916978  1356.860599  \n",
       "\n",
       "[1 rows x 66 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photons_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Cluster Shape..\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rawCLEi:\n",
    "    final_shape = ['ClE1', 'ClE2', 'ClE3', 'ClE4', 'ClE5', 'ClE6', 'ClE7', 'ClE8', 'ClE9', 'ClE10', 'ClE11', 'ClE12', 'ClE13', 'ClE14', 'ClE15', 'ClE16', 'ClE17', 'ClE18', 'ClE19', 'ClE20', 'ClE21', 'ClE22', 'ClE23', 'ClE24', 'ClE25']\n",
    "    shape = ['ClE1', 'ClE2', 'ClE3', 'ClE4', 'ClE5', 'ClE6', 'ClE7', 'ClE8', 'ClE9', 'ClE10', 'ClE11', 'ClE12', 'ClE13', 'ClE14', 'ClE15', 'ClE16', 'ClE17', 'ClE18', 'ClE19', 'ClE20', 'ClE21', 'ClE22', 'ClE23', 'ClE24', 'ClE25']\n",
    "elif rawDigEi:\n",
    "    final_shape = ['DigE1', 'DigE2', 'DigE3', 'DigE4', 'DigE5', 'DigE6',\n",
    "       'DigE7', 'DigE8', 'DigE9', 'DigE10', 'DigE11', 'DigE12',\n",
    "       'DigE13', 'DigE14', 'DigE15', 'DigE16', 'DigE17', 'DigE18',\n",
    "       'DigE19', 'DigE20', 'DigE21', 'DigE22', 'DigE23', 'DigE24',\n",
    "       'DigE25']\n",
    "    shape = ['DigE1', 'DigE2', 'DigE3', 'DigE4', 'DigE5', 'DigE6',\n",
    "       'DigE7', 'DigE8', 'DigE9', 'DigE10', 'DigE11', 'DigE12',\n",
    "       'DigE13', 'DigE14', 'DigE15', 'DigE16', 'DigE17', 'DigE18',\n",
    "       'DigE19', 'DigE20', 'DigE21', 'DigE22', 'DigE23', 'DigE24',\n",
    "       'DigE25']\n",
    "elif original:\n",
    "    final_shape = ['isPhr2','isPhr2r4','isPhasym','isPhkappa','isPhEseed','isPhE2']\n",
    "    shape = ['ClE1', 'ClE2', 'ClE3', 'ClE4', 'ClE5', 'ClE6', 'ClE7', 'ClE8', 'ClE9', 'ClE10', 'ClE11', 'ClE12', 'ClE13', 'ClE14', 'ClE15', 'ClE16', 'ClE17', 'ClE18', 'ClE19', 'ClE20', 'ClE21', 'ClE22', 'ClE23', 'ClE24', 'ClE25']\n",
    "elif preOriginal:\n",
    "    final_shape = ['Sxx', 'Sxy', 'Syy']\n",
    "    shape = ['ClE1', 'ClE2', 'ClE3', 'ClE4', 'ClE5', 'ClE6', 'ClE7', 'ClE8', 'ClE9', 'ClE10', 'ClE11', 'ClE12', 'ClE13', 'ClE14', 'ClE15', 'ClE16', 'ClE17', 'ClE18', 'ClE19', 'ClE20', 'ClE21', 'ClE22', 'ClE23', 'ClE24', 'ClE25']\n",
    "elif rawCLEi_and_original:\n",
    "    final_shape = ['ClE1', 'ClE2', 'ClE3', 'ClE4', 'ClE5', 'ClE6', 'ClE7', 'ClE8', 'ClE9', 'ClE10', 'ClE11', 'ClE12', 'ClE13', 'ClE14', 'ClE15', 'ClE16', 'ClE17', 'ClE18', 'ClE19', 'ClE20', 'ClE21', 'ClE22', 'ClE23', 'ClE24', 'ClE25','isPhr2','isPhr2r4','isPhasym','isPhkappa','isPhEseed','isPhE2']\n",
    "    shape = ['ClE1', 'ClE2', 'ClE3', 'ClE4', 'ClE5', 'ClE6', 'ClE7', 'ClE8', 'ClE9', 'ClE10', 'ClE11', 'ClE12', 'ClE13', 'ClE14', 'ClE15', 'ClE16', 'ClE17', 'ClE18', 'ClE19', 'ClE20', 'ClE21', 'ClE22', 'ClE23', 'ClE24', 'ClE25']\n",
    "elif rawDigEi_and_original:\n",
    "    final_shape = ['DigE1', 'DigE2', 'DigE3', 'DigE4', 'DigE5', 'DigE6',\n",
    "       'DigE7', 'DigE8', 'DigE9', 'DigE10', 'DigE11', 'DigE12',\n",
    "       'DigE13', 'DigE14', 'DigE15', 'DigE16', 'DigE17', 'DigE18',\n",
    "       'DigE19', 'DigE20', 'DigE21', 'DigE22', 'DigE23', 'DigE24',\n",
    "       'DigE25','isPhr2','isPhr2r4','isPhasym','isPhkappa','isPhEseed','isPhE2']\n",
    "    shape = ['DigE1', 'DigE2', 'DigE3', 'DigE4', 'DigE5', 'DigE6',\n",
    "       'DigE7', 'DigE8', 'DigE9', 'DigE10', 'DigE11', 'DigE12',\n",
    "       'DigE13', 'DigE14', 'DigE15', 'DigE16', 'DigE17', 'DigE18',\n",
    "       'DigE19', 'DigE20', 'DigE21', 'DigE22', 'DigE23', 'DigE24',\n",
    "       'DigE25']\n",
    "elif rawCLEi_and_preOriginal:\n",
    "    final_shape = ['ClE1', 'ClE2', 'ClE3', 'ClE4', 'ClE5', 'ClE6', 'ClE7', 'ClE8', 'ClE9', 'ClE10', 'ClE11', 'ClE12', 'ClE13', 'ClE14', 'ClE15', 'ClE16', 'ClE17', 'ClE18', 'ClE19', 'ClE20', 'ClE21', 'ClE22', 'ClE23', 'ClE24', 'ClE25','Sxx', 'Sxy', 'Syy']\n",
    "    shape = ['ClE1', 'ClE2', 'ClE3', 'ClE4', 'ClE5', 'ClE6', 'ClE7', 'ClE8', 'ClE9', 'ClE10', 'ClE11', 'ClE12', 'ClE13', 'ClE14', 'ClE15', 'ClE16', 'ClE17', 'ClE18', 'ClE19', 'ClE20', 'ClE21', 'ClE22', 'ClE23', 'ClE24', 'ClE25']\n",
    "elif rawCLEi_and_original_and_preOriginal:\n",
    "    final_shape = ['ClE1', 'ClE2', 'ClE3', 'ClE4', 'ClE5', 'ClE6', 'ClE7', 'ClE8', 'ClE9', 'ClE10', 'ClE11', 'ClE12', 'ClE13', 'ClE14', 'ClE15', 'ClE16', 'ClE17', 'ClE18', 'ClE19', 'ClE20', 'ClE21', 'ClE22', 'ClE23', 'ClE24', 'ClE25','isPhr2','isPhr2r4','isPhasym','isPhkappa','isPhEseed','isPhE2','Sxx', 'Sxy', 'Syy']\n",
    "    shape = ['ClE1', 'ClE2', 'ClE3', 'ClE4', 'ClE5', 'ClE6', 'ClE7', 'ClE8', 'ClE9', 'ClE10', 'ClE11', 'ClE12', 'ClE13', 'ClE14', 'ClE15', 'ClE16', 'ClE17', 'ClE18', 'ClE19', 'ClE20', 'ClE21', 'ClE22', 'ClE23', 'ClE24', 'ClE25']\n",
    "\n",
    "\n",
    "# Original + Raw\n",
    "# final_shape = ['ClE1','ClE2','ClE3','ClE4','ClE5','ClE6','ClE7','ClE8','ClE9','isPhr2','isPhr2r4','isPhasym','isPhkappa','isPhEseed','isPhE2']\n",
    "#Raw\n",
    "#final_shape = ['ClE1', 'ClE2', 'ClE3', 'ClE4', 'ClE5', 'ClE6', 'ClE7', 'ClE8', 'ClE9', 'ClE10', 'ClE11', 'ClE12', 'ClE13', 'ClE14', 'ClE15', 'ClE16', 'ClE17', 'ClE18', 'ClE19', 'ClE20', 'ClE21', 'ClE22', 'ClE23', 'ClE24', 'ClE25']\n",
    "# Original\n",
    "#final_shape = ['isPhr2','isPhr2r4','isPhasym','isPhkappa','isPhEseed','isPhE2']\n",
    "#shape = ['ClE1', 'ClE2', 'ClE3', 'ClE4', 'ClE5', 'ClE6', 'ClE7', 'ClE8', 'ClE9', 'ClE10', 'ClE11', 'ClE12', 'ClE13', 'ClE14', 'ClE15', 'ClE16', 'ClE17', 'ClE18', 'ClE19', 'ClE20', 'ClE21', 'ClE22', 'ClE23', 'ClE24', 'ClE25']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data..\n",
    "- 0) Retrieve RAW data\n",
    "- 1) Rotate RAW matrices\n",
    "- 2) Normalise data\n",
    "- 3) Add Original Variables to data\n",
    "- 4) Add Labels to data\n",
    "- 5) Equilibrate category classes\n",
    "- 6) Merge both merged pi0 and photons data into single panda DataFrame -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -0\n",
    "m_d = pd.DataFrame()\n",
    "p_d = pd.DataFrame()\n",
    "data = pd.DataFrame()\n",
    "#Retrive important columns\n",
    "p_d = photons_data[list (shape)]\n",
    "m_d = mergedpi_data[list (shape)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_to_top_matrice(m):\n",
    "    max = 0\n",
    "        \n",
    "    top = m[1][2]\n",
    "    bot = m[3][2]\n",
    "    left = m[2][1]\n",
    "    right = m[2][3]\n",
    "    \n",
    "    if (top >= bot) & (top >= left) & (top >= right):\n",
    "        max = 0\n",
    "    elif (bot >= left) & (bot >= right):\n",
    "        max = 2\n",
    "    elif left >= right:\n",
    "        max = 3\n",
    "    else:\n",
    "        max = 1\n",
    "    \n",
    "    mat = np.rot90(m, max)\n",
    "    \n",
    "    top = m[1][2]\n",
    "    top_left = mat[1][1]\n",
    "    top_right = mat[1][3]\n",
    "    bot_left = mat[3][1]\n",
    "    bot_right = mat[3][3]\n",
    "    \n",
    "    max = 0\n",
    "    if (top_left >= top_right) & (top_left >= bot_left) & (top_left >= bot_right) & (top_left > top):\n",
    "        max = 0\n",
    "    elif (top_right >= bot_left) & (top_right >= bot_right) & (top_right > top):\n",
    "        max = 1\n",
    "    elif (bot_left >= bot_right) & (bot_left > top):\n",
    "        max = 3\n",
    "    elif bot_right > top:\n",
    "        max = 2\n",
    "         \n",
    "    \n",
    "    return np.rot90(mat, max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rotateToTop:\n",
    "    # -1\n",
    "    # Rotate matrices to top direction\n",
    "    p_d = pd.DataFrame(np.array([rotate_to_top_matrice(m) for m in p_d.values.reshape((-1, 5, 5, 1))]).reshape(-1,25))\n",
    "    p_d.columns = shape\n",
    "    m_d = pd.DataFrame(np.array([rotate_to_top_matrice(m) for m in m_d.values.reshape((-1, 5, 5, 1))]).reshape(-1,25))\n",
    "    m_d.columns = shape\n",
    "# -2\n",
    "#Normalise data\n",
    "    #Divide each cell with the entire energy at the cluster\n",
    "p_d = p_d[shape]\n",
    "m_d = m_d[shape]\n",
    "p_d = p_d.assign(suma = p_d.sum(axis=1));\n",
    "m_d = m_d.assign(suma = m_d.sum(axis=1));\n",
    "p_d_norm = (p_d.T / p_d.suma).T\n",
    "m_d_norm = (m_d.T / m_d.suma).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if original | rawCLEi_and_original | rawDigEi_and_original:\n",
    "    m_d_norm[['isPhr2','isPhr2r4','isPhasym','isPhkappa','isPhEseed','isPhE2']] = mergedpi_data[['isPhr2','isPhr2r4','isPhasym','isPhkappa','isPhEseed','isPhE2']]\n",
    "    p_d_norm[['isPhr2','isPhr2r4','isPhasym','isPhkappa','isPhEseed','isPhE2']] = photons_data[['isPhr2','isPhr2r4','isPhasym','isPhkappa','isPhEseed','isPhE2']]\n",
    "elif preOriginal | rawCLEi_and_preOriginal:\n",
    "    m_d_norm[['Sxx', 'Sxy', 'Syy']] = mergedpi_data[['Sxx', 'Sxy', 'Syy']]\n",
    "    p_d_norm[['Sxx', 'Sxy', 'Syy']] = photons_data[['Sxx', 'Sxy', 'Syy']]\n",
    "    \n",
    "if rawCLEi_and_original_and_preOriginal:\n",
    "    m_d_norm[['isPhr2','isPhr2r4','isPhasym','isPhkappa','isPhEseed','isPhE2','Sxx', 'Sxy', 'Syy']] = mergedpi_data[['isPhr2','isPhr2r4','isPhasym','isPhkappa','isPhEseed','isPhE2','Sxx', 'Sxy', 'Syy']]\n",
    "    p_d_norm[['isPhr2','isPhr2r4','isPhasym','isPhkappa','isPhEseed','isPhE2','Sxx', 'Sxy', 'Syy']] = photons_data[['isPhr2','isPhr2r4','isPhasym','isPhkappa','isPhEseed','isPhE2','Sxx', 'Sxy', 'Syy']]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -4\n",
    "#Add Labels to data\n",
    "m_d_norm['area'] = mergedpi_data[['area']]\n",
    "p_d_norm['area'] = photons_data[['area']]\n",
    "\n",
    "#Add category = 0 column to dataframe, so we identify merged pi0 as 0\n",
    "m_d_norm = m_d_norm.assign(category=pd.Series(np.full((len(m_d_norm['area'])), 0)).values)\n",
    "\n",
    "#Add category = 1 column to dataframe, so we identify photons as 1\n",
    "p_d_norm = p_d_norm.assign(category=pd.Series(np.full((len(p_d_norm['area'])), 1)).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -5 \n",
    "# Equilibrate category classes\n",
    "p_d_norm_0 = p_d_norm[p_d_norm['area'] == 0]\n",
    "p_d_norm_0 = p_d_norm_0.iloc[0:len(m_d_norm[m_d_norm['area'] == 0])]\n",
    "\n",
    "p_d_norm_1 = p_d_norm[p_d_norm['area'] == 1]\n",
    "p_d_norm_1 = p_d_norm_1.iloc[0:len(m_d_norm[m_d_norm['area'] == 1])]\n",
    "\n",
    "p_d_norm_2 = p_d_norm[p_d_norm['area'] == 2]\n",
    "p_d_norm_2 = p_d_norm_2.iloc[0:len(m_d_norm[m_d_norm['area'] == 2])]\n",
    "\n",
    "print (len(p_d_norm_0) + len(p_d_norm_1) + len(p_d_norm_2) == len(m_d_norm))\n",
    "p_d_norm = p_d_norm_0.append(p_d_norm_1).append(p_d_norm_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -6\n",
    "#Merge both mergedpi0 and photons into a single datagrame\n",
    "data = m_d_norm.append(p_d_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA ANALYZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if plot_analysis:\n",
    "\n",
    "    x = [i for range_set in range(5) for i in range (1,6)]\n",
    "    y = sorted(x, reverse=True)\n",
    "\n",
    "    single_m_0 = np.array(m_d_norm[m_d_norm['area'] == 0][shape])[0]\n",
    "    single_m_1 = np.array(m_d_norm[m_d_norm['area'] == 1][shape])[0]\n",
    "    single_m_2 = np.array(m_d_norm[m_d_norm['area'] == 2][shape])[0]\n",
    "\n",
    "    single_p_0 = np.array(p_d_norm[p_d_norm['area'] == 0][shape])[0]\n",
    "    single_p_1 = np.array(p_d_norm[p_d_norm['area'] == 1][shape])[0]\n",
    "    single_p_2 = np.array(p_d_norm[p_d_norm['area'] == 2][shape])[0]\n",
    "\n",
    "\n",
    "    mean_m_0 = (m_d_norm[m_d_norm['area'] == 0][shape].values).mean(axis=0)\n",
    "    mean_m_1 = (m_d_norm[m_d_norm['area'] == 1][shape].values).mean(axis=0)\n",
    "    mean_m_2 = (m_d_norm[m_d_norm['area'] == 2][shape].values).mean(axis=0)\n",
    "\n",
    "    mean_p_0 = (p_d_norm[p_d_norm['area'] == 0][shape].values).mean(axis=0)\n",
    "    mean_p_1 = (p_d_norm[p_d_norm['area'] == 1][shape].values).mean(axis=0)\n",
    "    mean_p_2 = (p_d_norm[p_d_norm['area'] == 2][shape].values).mean(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def plot_cluster_comparasion(weight_0, weight_1):\n",
    "        f, (ax) = plt.subplots(1, 2, figsize=(12,5),sharex=True, sharey=True, constrained_layout=True)\n",
    "        levels = np.linspace(0, 1)\n",
    "        im = ax[0].hist2d(x, y, (5, 5), weights=weight_0, cmap=plt.cm.jet, vmin=0, vmax=1)\n",
    "        ax[1].hist2d(x, y, (5, 5), weights=weight_1, cmap=plt.cm.jet,vmin=0, vmax=1)\n",
    "\n",
    "        plt.colorbar(im[3]);\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    plot_cluster_comparasion(mean_m_0, mean_p_0)\n",
    "    plot_cluster_comparasion(mean_m_1, mean_p_1)\n",
    "    plot_cluster_comparasion(mean_m_2, mean_p_2)\n",
    "    plot_cluster_comparasion(single_m_0, single_p_0)\n",
    "    plot_cluster_comparasion(single_m_1, single_p_1)\n",
    "    plot_cluster_comparasion(single_m_2, single_p_2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost..\n",
    "- 0) Divide into train and test\n",
    "- 1) Fit into DMatrix\n",
    "- 2) CrossValidation\n",
    "- 3) Train!\n",
    "- 4) Test\n",
    "- 5) Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to divide data\n",
    "#Param area [0,1,2] ECAL area\n",
    "#test_fraction, the fraction of data to preserve for test\n",
    "def divide_data(area, test_fraction):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[data['area'] == area][final_shape],\n",
    "                                                data[data['area'] == area][['category']], test_size=test_fraction, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "def fit_data(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    #DMatrix object takes as arguments:\n",
    "    #    - data --- the features\n",
    "    #    - label --- 1/0 or true/false for binary data (so set 0 = merged pi 0, 1 = photon)\n",
    "    #    - feature_names --- the names of all of the features (optional)\n",
    "    feature_names=final_shape\n",
    "    train = xgb.DMatrix(data=X_train,label=y_train,feature_names=feature_names)\n",
    "    test = xgb.DMatrix(data=X_test,label=y_test,feature_names=feature_names)\n",
    "    return train, test\n",
    "\n",
    "#Tree parameters\n",
    "param = {'eta': 0.02, \n",
    "          'max_depth': 10, \n",
    "          'subsample': 0.8, \n",
    "          'colsample_bytree': 0.8, \n",
    "          'objective': 'binary:logistic', \n",
    "          'seed': 0, \n",
    "          'silent': 1,\n",
    "         'eval_metric': 'auc'}\n",
    "n_folds = 5\n",
    "early_stopping = 10\n",
    "num_trees = 1000  # number of trees to make\n",
    "\n",
    "#CV + XGBoost train\n",
    "def train_tree(param, n_folds, early_stopping, num_trees, train):\n",
    "    #cv = xgb.cv(param, train, 5000, nfold=n_folds, early_stopping_rounds=early_stopping)\n",
    "   # print (param)\n",
    "    booster = xgb.train(param,train,num_boost_round=num_trees)\n",
    "    return booster\n",
    "\n",
    "def test_tree(booster, test):\n",
    "    #Predict test results\n",
    "    predictions = booster.predict(test)\n",
    "    return predictions\n",
    "\n",
    "def plot_category_predictions(predictions, test, area, fold, data_title = title):\n",
    "    \n",
    "    #xgb.plot_importance(booster,grid=True);\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,10));\n",
    "    plt.hist(predictions[test.get_label().astype(bool)],bins=np.linspace(0,1,50),\n",
    "             histtype='step',color='midnightblue',label='$\\gamma$');\n",
    "    plt.hist(predictions[~(test.get_label().astype(bool))],bins=np.linspace(0,1,50),\n",
    "             histtype='step',color='firebrick',label='$\\pi$');\n",
    "    # make the plot readable\n",
    "    plt.xlabel('Prediction from BDT',fontsize=12);\n",
    "    plt.ylabel('Samples',fontsize=12);\n",
    "    plt.legend(frameon=False);\n",
    "    plt.title(\"%s Area; Fold %d; %s; XGBoost\" % (area, fold, data_title) ,fontsize=13);\n",
    "    return fig\n",
    "\n",
    "def CV_xgboost_tree_from_trained_booster(X, Y, booster, nsplits = 5):\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=nsplits, shuffle=True, random_state = 42)\n",
    "    \n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    i = 0\n",
    "    tests = []\n",
    "    predictions = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    for itrain, itest in cv.split(X, Y):\n",
    "        train, test = fit_data(np.array(X.iloc[itrain]), np.array(X.iloc[itest]),np.array(Y.iloc[itrain]), np.array(Y.iloc[itest]))\n",
    "        tests.append(test)\n",
    "        predictions.append(booster[i].predict(test))\n",
    "        #plot_results(booster[i], predictions, 'XGBoost; outter area; Raw Data')\n",
    "        #xgb.plot_importance(booster[i],grid=True);\n",
    "        fpr, tpr, threshold = metrics.roc_curve(np.array(Y.iloc[itest]), predictions[i])\n",
    "\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        \n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "       \n",
    "        i += 1\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    \n",
    "\n",
    "    \n",
    "    return predictions, tests, mean_fpr, mean_tpr, mean_auc, std_auc, plt, fig\n",
    "\n",
    "def CV_xgboost_tree(X, Y, nsplits = 5):\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=nsplits, shuffle=True, random_state = 42)\n",
    "    \n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    i = 0\n",
    "    booster = []\n",
    "    predictions = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for itrain, itest in cv.split(X, Y):\n",
    "        train, test = fit_data(np.array(X.iloc[itrain]), np.array(X.iloc[itest]),np.array(Y.iloc[itrain]), np.array(Y.iloc[itest]))\n",
    "        booster.append(xgb.train(param,train,num_boost_round=num_trees))\n",
    "        predictions.append(booster[i].predict(test))\n",
    "        \n",
    "        #plot_results(booster[i], predictions, 'XGBoost; outter area; Raw Data')\n",
    "        #xgb.plot_importance(booster[i],grid=True);\n",
    "        fpr, tpr, threshold = metrics.roc_curve(np.array(Y.iloc[itest]), predictions[i])\n",
    "\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        \n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "        print(i)\n",
    "        i += 1\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    \n",
    "\n",
    "    \n",
    "    return booster, predictions, mean_fpr, mean_tpr, mean_auc, std_auc, plt\n",
    "\n",
    "\n",
    "def plot_results(mean_fpr, mean_tpr, mean_auc, std_auc, plot, color, title):\n",
    "    plot.plot(mean_fpr, mean_tpr, color=color, label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "             lw=2, alpha=.8)\n",
    "    plot.xlim([-0.01, 1.01])\n",
    "    plot.ylim([-0.01, 1.01])\n",
    "    plot.legend(loc = 'lower right')\n",
    "    plot.ylabel('$\\gamma$ efficiency')\n",
    "    plot.xlabel('$\\pi^0$ efficiency')\n",
    "    plot.title(title)\n",
    "    plot.show()\n",
    "    \n",
    "def save_models():\n",
    "    for i in range(KFolds):\n",
    "        out_boosters[i].save_model('%s0_Fold%d_.model' % (save_boosters_path, i))\n",
    "        mid_boosters[i].save_model('%s1_Fold%d_.model' % (save_boosters_path, i))\n",
    "        in_boosters[i].save_model('%s2_Fold%d_.model' % (save_boosters_path, i))\n",
    "\n",
    "def load_models():\n",
    "    out_boosters = []\n",
    "    mid_boosters = []\n",
    "    in_boosters = []\n",
    "    for i in range(KFolds):\n",
    "        out_boosters.append(xgb.Booster({'nthread': 4}))  # init model\n",
    "        out_boosters[i].load_model('%s0_Fold%d_.model' % (save_boosters_path, i))  # load data\n",
    "        mid_boosters.append(xgb.Booster({'nthread': 4}))  # init model\n",
    "        mid_boosters[i].load_model('%s1_Fold%d_.model' % (save_boosters_path, i))  # load data\n",
    "        in_boosters.append(xgb.Booster({'nthread': 4}))  # init model\n",
    "        in_boosters[i].load_model('%s2_Fold%d_.model' % (save_boosters_path, i))  # load data\n",
    "    return out_boosters, mid_boosters, in_boosters\n",
    "\n",
    "  \n",
    "def reproduce_results(path, data_title = title):\n",
    "    out_boosters, mid_boosters, in_boosters = load_models()\n",
    "    X_train, X_test, y_train, y_test = divide_data(2,0)\n",
    "    in_predictions, in_tests, in_mean_fpr, in_mean_tpr, in_mean_auc, in_std_auc, in_plot, in_fig = CV_xgboost_tree_from_trained_booster(X_train,y_train,in_boosters, KFolds)\n",
    "    plot_results(in_mean_fpr, in_mean_tpr, in_mean_auc, in_std_auc, in_plot, 'b', \"Inner Area; %s; XGBoost\" % data_title)\n",
    "    in_fig.savefig('%s2.png' % (path))\n",
    "    for i in range(KFolds):\n",
    "        in_fig = plot_category_predictions(in_predictions[i], in_tests[i], 'Inner', i)\n",
    "        in_fig.savefig('%s2_fold%d.png' % (path,i))\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = divide_data(1,0)\n",
    "    mid_predictions, mid_tests, mid_mean_fpr, mid_mean_tpr, mid_mean_auc, mid_std_auc, mid_plot, mid_fig = CV_xgboost_tree_from_trained_booster(X_train,y_train, mid_boosters, KFolds)\n",
    "    plot_results(mid_mean_fpr, mid_mean_tpr, mid_mean_auc, mid_std_auc, mid_plot, 'g', \"Middle Area; %s; XGBoost\" % data_title)\n",
    "    mid_fig.savefig('%s1.png' % (path))\n",
    "    for i in range(KFolds):\n",
    "        mid_fig = plot_category_predictions(mid_predictions[i], mid_tests[i], 'Middle', i)\n",
    "        mid_fig.savefig('%s1_fold%d.png' % (path,i))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = divide_data(0,0)\n",
    "    out_predictions, out_tests, out_mean_fpr, out_mean_tpr, out_mean_auc, out_std_auc, out_plot, out_fig = CV_xgboost_tree_from_trained_booster(X_train,y_train, out_boosters, KFolds)\n",
    "    plot_results(out_mean_fpr, out_mean_tpr, out_mean_auc, out_std_auc, out_plot, 'r', \"Outer Area; %s; XGBoost\" % data_title)\n",
    "    out_fig.savefig('%s0.png' % (path))\n",
    "    for i in range(KFolds):\n",
    "        out_fig = plot_category_predictions(out_predictions[i], out_tests[i], 'Outer', i)\n",
    "        out_fig.savefig('%s0_fold%d.png' % (path,i))\n",
    "    \n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "\n",
    "    tprs.append(interp(mean_fpr, in_mean_fpr, in_mean_tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    aucs.append(in_mean_auc)\n",
    "\n",
    "    tprs.append(interp(mean_fpr, out_mean_fpr, out_mean_tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    aucs.append(out_mean_auc)\n",
    "\n",
    "    tprs.append(interp(mean_fpr, mid_mean_fpr, mid_mean_tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    aucs.append(mid_mean_auc)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "\n",
    "\n",
    "    final_fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "    plt.plot(out_mean_fpr, out_mean_tpr, color='r', label=r'Outer Area Mean ROC (AUC = %0.2f)' % (out_mean_auc),\n",
    "                 lw=2, alpha=.8)\n",
    "    plt.plot(mid_mean_fpr, mid_mean_tpr, color='g', label=r'Middle Area Mean ROC (AUC = %0.2f)' % (mid_mean_auc),\n",
    "                 lw=2, alpha=.8)\n",
    "    plt.plot(in_mean_fpr, in_mean_tpr, color='b', label=r'Inner Area Mean ROC (AUC = %0.2f)' % (in_mean_auc),\n",
    "                 lw=2, alpha=.8)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='c', label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "                 lw=2, alpha=.8)\n",
    "\n",
    "    plt.xlim([-0.01, 1.01])\n",
    "    plt.ylim([-0.01, 1.01])\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.title('XGBoost; %s; Mean AUC' % data_title)\n",
    "    plt.ylabel('$\\gamma$ efficiency')\n",
    "    plt.xlabel('$\\pi^0$ efficiency')\n",
    "    final_fig.savefig('%s0_1_2.png' % path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = divide_data(0,0) # IMPORTANT IT ALSO ROTATES DATA\n",
    "out_boosters, out_predictions, out_mean_fpr, out_mean_tpr, out_mean_auc, out_std_auc, out_plot = CV_xgboost_tree(X_train,y_train, KFolds)\n",
    "\n",
    "plot_results(out_mean_fpr, out_mean_tpr, out_mean_auc, out_std_auc, out_plot, 'r', \"Outer Area; %s; XGBoost\" % title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = divide_data(1,0) # IMPORTANT IT ALSO ROTATES DATA\n",
    "mid_boosters, mid_predictions, mid_mean_fpr, mid_mean_tpr, mid_mean_auc, mid_std_auc, mid_plot = CV_xgboost_tree(X_train,y_train, KFolds)\n",
    "\n",
    "plot_results(mid_mean_fpr, mid_mean_tpr, mid_mean_auc, mid_std_auc, mid_plot, 'g', \"Middle Area; %s; XGBoost\" % title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = divide_data(2,0) # IMPORTANT IT ALSO ROTATES DATA\n",
    "in_boosters, in_predictions, in_mean_fpr, in_mean_tpr, in_mean_auc, in_std_auc, in_plot = CV_xgboost_tree(X_train,y_train, KFolds)\n",
    "\n",
    "plot_results(in_mean_fpr, in_mean_tpr, in_mean_auc, in_std_auc, in_plot, 'b', \"Inner Area; %s; XGBoost\" % title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if save_results:\n",
    "    save_models()\n",
    "    reproduce_results(save_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
